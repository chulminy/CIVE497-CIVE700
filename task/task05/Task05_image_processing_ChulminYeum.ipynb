{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task05: Image Processing\n",
    "\n",
    "* **Your Name:** \n",
    "* **Your ID:** \n",
    "\n",
    "**For the sample demonstration videos, an interactive feature has been included. While you have the option to incorporate this feature into your application, it is not mandatory. You will still receive full marks as long as your application successfully produces the resulting images.**\n",
    "\n",
    "Last updated: Feb 26, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: 2D Convolution (20 points)\n",
    "The general expression of a 2D convolution is\n",
    " \n",
    "![](https://latex.codecogs.com/gif.latex?G%5Bi%2Cj%5D%3D%5Csum_%7Bu%3D-k%7D%5E%7Bk%7D%20%5Csum_%7Bv%3D-k%7D%5E%7Bk%7D%20H%5Bu%2Cv%5D%20F%5Bi-u%2C%20j-v%5D)\n",
    "\n",
    "where G is the filtered image, F is the original image, and H is the kernel.  \n",
    "\n",
    "You first take a colour picture or download any colour image on the web, and resize the image to have 400 pixel in the shortest side. For example, if your image 5000 x 4000 pixel, it becomes 500x400 pixel. Then, please do the convolution of the resized image and the kernel H:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?h%20%3D%20%5Cbegin%7Bbmatrix%7D%200%20%26-0.5%20%260%20%5C%5C%20-0.5%20%26%202%20%26%20-0.5%5C%5C%200%26%20-0.5%26%200%20%5Cend%7Bbmatrix%7D)\n",
    "\n",
    "(a) Please compute G using [`scipy.signal.convolve2d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html)\n",
    "\n",
    "(b) Please compute G using your own code (use of a for-loop structure).\n",
    "\n",
    "Note that answers for (a) and (b) must be the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Different Kernels (20 points)\n",
    "\n",
    "You are going to filter your image using the following kernels. Please conduct convolution of your image (used in Problem 1) with the kernel H1, H2, H3, H4, and H5, respectively. Then, you need to explain the effect of filtering with the each kernel with the resulting images. \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?H_1%20%3D%20%5Cfrac%7B1%7D%7B9%7D%5Cbegin%7Bbmatrix%7D%201%20%26%201%20%26%201%5C%5C%201%20%26%201%20%26%201%5C%5C%201%20%26%201%20%26%201%20%5Cend%7Bbmatrix%7D%2C%5C%2C%5C%2C%20H_2%20%3D%20%5Cbegin%7Bbmatrix%7D%200%20%26%201%20%26%200%5C%5C%201%20%26%20-4%20%26%201%5C%5C%200%20%26%201%20%26%200%20%5Cend%7Bbmatrix%7D%20%2C%20%5C%2C%5C%2C%20H_3%20%3D%20%5Cbegin%7Bbmatrix%7D%20-0.55%20%26%20-0.55%20%26%20-0.55%5C%5C%20-0.55%20%26%205.40%20%26%20-0.55%5C%5C%20-0.55%20%26%20-0.55%20%26%20-0.55%20%5Cend%7Bbmatrix%7D%20%2C)\n",
    "</br>\n",
    "![](https://latex.codecogs.com/gif.latex?H_4%20%3D%20%5Cbegin%7Bbmatrix%7D%200.0030%20%26%200.0133%20%26%200.0219%20%26%200.0133%20%26%200.0030%20%5C%5C%200.0133%20%26%200.0596%20%26%200.0983%20%26%200.0596%20%26%200.0133%20%5C%5C%200.0219%20%26%200.0983%20%26%200.1621%20%26%200.0983%20%26%200.0219%20%5C%5C%200.0133%20%26%200.0596%20%26%200.0983%20%26%200.0596%20%26%200.0133%20%5C%5C%200.0030%20%26%200.0133%20%26%200.0219%20%26%200.0133%20%26%200.0030%20%5Cend%7Bbmatrix%7D) ![](https://latex.codecogs.com/gif.latex?,) &nbsp;&nbsp;&nbsp;   ![](https://latex.codecogs.com/gif.latex?H_5%20%3D%20%5Cbegin%7Bbmatrix%7D%200%20%26%200%20%26%200%26%200%26%200%5C%5C%200%20%26%200%20%26%200%20%26%200%20%26%200%5C%5C%200%20%26%200%20%26%200%20%26%200%20%26%201%5C%5C%200%20%26%200%20%26%200%20%26%200%20%26%200%5C%5C%200%20%26%200%20%26%200%20%26%200%20%26%200%20%5Cend%7Bbmatrix%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Gaussian Kernel (10 points)\n",
    "\n",
    "**Review a `fspecial` function in MATLAB and produce the same operation in Python**\n",
    "\n",
    "(a) Write a code to create the following Gaussian kernel h without using `fspecial`. \n",
    "\n",
    "```matlab\n",
    "h = fspecial('gaussian', 11, 3);\n",
    "```\n",
    "You need to use a theoretical Gaussian curve to get the value of each element in h. Your code produces the kernel close to h obtained from the `fspecial` function.   \n",
    "\n",
    "(b) What is the difference between the kernel h1 and h2 in terms of the effect on the  images filtered with these kernels? You can explain it with sample results.    \n",
    "\n",
    "```matlab    \n",
    "h1 = fspecial('gaussian', 20, 2);\n",
    "h2 = fspecial('gaussian', 20, 4);\n",
    "```\n",
    "\n",
    "(c) What is the difference between the kernel h2 and h3 in terms of the effect on the  images filtered with these kernels? Are they different? You can explain it with sample results.   \n",
    "\n",
    "```matlab   \n",
    "h2 = fspecial('gaussian', 11, 3);\n",
    "h3 = fspecial('gaussian', 51, 3);\n",
    "```\n",
    "\n",
    "(d) What is the difference between the kernel h2 and h4 in terms of the effect on the  images filtered with these kernels? Are they different? You can explain it with sample results.   \n",
    "\n",
    "```matlab   \n",
    "h2 = fspecial('gaussian', 11, 3);\n",
    "h4 = fspecial('gaussian', 21, 21);\n",
    "```\n",
    "Please **ignore** the boundary effect. You can do either zero-padding (e.g., `same` option in `conv2` in MATLAB) or get the valid area (e.g., `valid` option in `conv2` in MATLAB).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Hough Transform (20 points)\n",
    "\n",
    "Create a program that automatically extracts and corrects the perspective distortion of booklet images from provided pictures. \n",
    "Below is the starting code for your implementation. This requires developing a `FindCorner` function to detect the booklet's corners via edge detection and the Hough transform. You may also need to use your `ComputeH` function from a previous task to adjust the perspective. Note that the process could flip the images horizontally or vertically. \n",
    "\n",
    "You're encouraged to use a custom Hough Transform implementation from a suggested online resource, although any suitable library is acceptable for completing the task.\n",
    "\n",
    "Please review the following Hough Transformation implementation: \n",
    "[https://gist.github.com/bygreencn/6a900fd2ff5d0101473acbc3783c4d92](https://gist.github.com/bygreencn/6a900fd2ff5d0101473acbc3783c4d92)\n",
    "\n",
    "\n",
    "Here is a demo of my implementation:   \n",
    "[![](http://img.youtube.com/vi/d7EGfSoz28U/0.jpg)](https://youtu.be/d7EGfSoz28U)\n",
    "\n",
    "Your code successfully processes and rectifies all booklet images located in the 'problem4/img' folder, saving them in 'problem4/out' as demonstrated in the preceding video.\n",
    "\n",
    "**Next**, you are required to capture photographs and showcase your code's functionality using your own images. Ensure your submission encompasses both the outcomes and the code utilized.\n",
    "\n",
    "Hint: Here are the list of the functions used: `cv2.GaussianBlur`, `cv2.Canny`, `hough_lines_acc`, `hough_peaks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Please review the following code: \n",
    "# https://gist.github.com/bygreencn/6a900fd2ff5d0101473acbc3783c4d92\n",
    "\n",
    "# This is the function that will build the Hough Accumulator for the given image\n",
    "def hough_lines_acc(img, rho_resolution=1, theta_resolution=1):\n",
    "    ''' A function for creating a Hough Accumulator for lines in an image. '''\n",
    "    height, width = img.shape # we need heigth and width to calculate the diag\n",
    "    img_diagonal = np.ceil(np.sqrt(height**2 + width**2)) # a**2 + b**2 = c**2\n",
    "    rhos = np.arange(-img_diagonal, img_diagonal + 1, rho_resolution)\n",
    "    thetas = np.deg2rad(np.arange(-90, 90, theta_resolution))\n",
    "\n",
    "    # create the empty Hough Accumulator with dimensions equal to the size of\n",
    "    # rhos and thetas\n",
    "    H = np.zeros((len(rhos), len(thetas)), dtype=np.uint64)\n",
    "    y_idxs, x_idxs = np.nonzero(img) # find all edge (nonzero) pixel indexes\n",
    "\n",
    "    for i in range(len(x_idxs)): # cycle through edge points\n",
    "        x = x_idxs[i]\n",
    "        y = y_idxs[i]\n",
    "\n",
    "        for j in range(len(thetas)): # cycle through thetas and calc rho\n",
    "            rho = int((x * np.cos(thetas[j]) +\n",
    "                       y * np.sin(thetas[j])) + img_diagonal)\n",
    "            H[rho, j] += 1\n",
    "\n",
    "    return H, rhos, thetas\n",
    "\n",
    "# This more advance Hough peaks funciton has threshold and nhood_size arguments\n",
    "# threshold will threshold the peak values to be above this value if supplied,\n",
    "# where as nhood_size will surpress the surrounding pixels centered around\n",
    "# the local maximum after that value has been assigned as a peak.  This will\n",
    "# force the algorithm to look eslwhere after it's already selected a point from\n",
    "# a 'pocket' of local maxima.\n",
    "def hough_peaks(H, num_peaks, threshold=0, nhood_size=3):\n",
    "    ''' A function that returns the indicies of the accumulator array H that\n",
    "        correspond to a local maxima.  If threshold is active all values less\n",
    "        than this value will be ignored, if neighborhood_size is greater than\n",
    "        (1, 1) this number of indicies around the maximum will be surpessed. '''\n",
    "    # loop through number of peaks to identify\n",
    "    indicies = []\n",
    "    H1 = np.copy(H)\n",
    "    for i in range(num_peaks):\n",
    "        idx = np.argmax(H1) # find argmax in flattened array\n",
    "        H1_idx = np.unravel_index(idx, H1.shape) # remap to shape of H\n",
    "        indicies.append(H1_idx)\n",
    "\n",
    "        # surpess indicies in neighborhood\n",
    "        idx_y, idx_x = H1_idx # first separate x, y indexes from argmax(H)\n",
    "        # if idx_x is too close to the edges choose appropriate values\n",
    "        if (idx_x - (nhood_size/2)) < 0: min_x = 0\n",
    "        else: min_x = idx_x - (nhood_size/2)\n",
    "        if ((idx_x + (nhood_size/2) + 1) > H.shape[1]): max_x = H.shape[1]\n",
    "        else: max_x = idx_x + (nhood_size/2) + 1\n",
    "\n",
    "        # if idx_y is too close to the edges choose appropriate values\n",
    "        if (idx_y - (nhood_size/2)) < 0: min_y = 0\n",
    "        else: min_y = idx_y - (nhood_size/2)\n",
    "        if ((idx_y + (nhood_size/2) + 1) > H.shape[0]): max_y = H.shape[0]\n",
    "        else: max_y = idx_y + (nhood_size/2) + 1\n",
    "\n",
    "        min_x = int(min_x)\n",
    "        max_x = int(max_x)\n",
    "        min_y = int(min_y)\n",
    "        max_y = int(max_y)\n",
    "\n",
    "        # bound each index by the neighborhood size and set all values to 0\n",
    "        for x in range(min_x, max_x):\n",
    "            for y in range(min_y, max_y):\n",
    "                # remove neighborhoods in H1\n",
    "                H1[y, x] = 0\n",
    "\n",
    "                # highlight peaks in original H\n",
    "                if (x == min_x or x == (max_x - 1)):\n",
    "                    H[y, x] = 255\n",
    "                if (y == min_y or y == (max_y - 1)):\n",
    "                    H[y, x] = 255\n",
    "\n",
    "    # return the indicies and the original Hough space with selected points\n",
    "    return indicies, H\n",
    "\n",
    "def hough_lines_draw(img, indicies, rhos, thetas):\n",
    "    ''' A function that takes indicies a rhos table and thetas table and draws\n",
    "        lines on the input images that correspond to these values. '''\n",
    "    for i in range(len(indicies)):\n",
    "        # reverse engineer lines from rhos and thetas\n",
    "        rho = rhos[indicies[i][0]]\n",
    "        theta = thetas[indicies[i][1]]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        # these are then scaled so that the lines go off the edges of the image\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "def FindCorner(img):\n",
    "    \n",
    "    # WRITE YOUR OWN CODE\n",
    "    \n",
    "    return corner\n",
    "\n",
    "def ComputeH(src, dst):\n",
    "\n",
    "    # WRITE YOUR OWN CODE\n",
    "\n",
    "    return H\n",
    "\n",
    "# Parameters\n",
    "bookletImgSize = [720, 945]  # output image size in pixels (set this manually)\n",
    "\n",
    "dirFolder = 'problem4'\n",
    "dirOut = os.path.join(dirFolder, 'out') # output folder\n",
    "imgList = glob(os.path.join(dirFolder, 'img', '*.JPG'))\n",
    "\n",
    "for imgPath in imgList:\n",
    "    img = cv2.imread(imgPath)\n",
    "    \n",
    "    # Step 1: Find ordered four corners. Implement or use your own FindCorner equivalent\n",
    "    corner = FindCorner(img)  # You need to implement or replace this\n",
    "    \n",
    "    # Compute a homography. Implement or use your own ComputeH equivalent\n",
    "    x, y, w, h = 0, 0, bookletImgSize[0], bookletImgSize[1]  # Example rectangle\n",
    "    \n",
    "    # Step 2: Find a homography between the corner and booklet image\n",
    "    H = ComputeH(corner, [[x, y],[x+w,y],[x+w, y+h],[x, y+h]] )  \n",
    "\n",
    "    # Remove perspective\n",
    "    imgTran = cv2.warpPerspective(img, (H), (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Crop the image with integer indices\n",
    "    bookletImg = imgTran[y:y+h, x:x+w]\n",
    "\n",
    "    # Save the transformed image\n",
    "    fileName = os.path.basename(imgPath)\n",
    "    cv2.imwrite(os.path.join(dirOut, fileName), bookletImg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Fiducial Marker Detection (30 points) \n",
    "You are going to build a marker code identification tool. Aruco marker (Augmented Reality University of Cordoba) is a popular fiducial marker widely used for augmented reality applications. Acruco marker is a binary square with black background and white generated pattern. Each marker has own unique id ranging from 0 to 999. The marker code is unique under a rotated environment. For example, although you rotate the marker 90 degrees, the code (white) pattern does not overlap with the ones from the rest of the 998 codes. I generated five 4 x 4 Aruco marker from [here](https://chev.me/arucogen/) where ID is from 1 to 5 and print them.  \n",
    "\n",
    "|![](problem5/marker_number.png)|![](problem5/marker.png)|\n",
    "|:-----:|:----:|\n",
    "|**(a) Five Aruco markers used in this problem**|**(b) a 4 x 4 maker design**|\n",
    "\n",
    "The objective of the tool is to identify the id of a marker on a given image. You are going to select the outline of the marker and your tool identify the id of the maker. A total of 7 images are given and you need to estimate the ids for the markers on these images. The Aruco marker binary pattern matrices for these markers are provided in `aruco_marker.mat`. You need to use this matrix to identify the id of the marker on each test image.   \n",
    "\n",
    "You are going to make your own `find_aruco_num` script to generate the following image.   \n",
    "![](problem5/result.png)  \n",
    "\n",
    "Note that you **must not** use any computer vision library related to marker detection. You can solve this using `ComputeH` that you made and some basic functions. \n",
    "Note that this is not a feature matching problem so do not try to match features on the marker on the test image and original marker image. \n",
    "\n",
    "\n",
    "Here is a sample demo. \n",
    "\n",
    "[![](http://img.youtube.com/vi/fQtPU3dNAgk/0.jpg)](https://youtu.be/fQtPU3dNAgk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load the ArUco marker data\n",
    "# Assuming 'aruco_marker' is a NumPy array of shape (height, width, num_markers) where each slice along the third axis is a binary image of a marker.\n",
    "mat = loadmat(f'problem5/aruco_marker.mat')\n",
    "\n",
    "# Access variables stored in mat\n",
    "aruco_marker = mat['aruco_marker']\n",
    "\n",
    "# Function to find ArUco marker number\n",
    "def find_aruco_num(img, corners, aruco_marker):\n",
    "    \n",
    "    # WRITE YOUR OWN CODE\n",
    "    \n",
    "    return marker_num\n",
    "\n",
    "def ComputeH(src, dst):\n",
    "\n",
    "    # WRITE YOUR OWN CODE\n",
    "\n",
    "    return H\n",
    "\n",
    "dirFolder = 'problem5'\n",
    "\n",
    "# Provided all corners\n",
    "gt_marker = [5, 2, 4, 3, 3, 4, 1]\n",
    "\n",
    "corners = [None]*7\n",
    "corners[0] = np.array([[1795,153], [2829,755], [1949,1749], [837,881]])\n",
    "corners[1] = np.array([[1661, 292], [2799, 686], [2219, 1814], [923, 1202]])\n",
    "corners[2] = np.array([[1875, 469], [2631, 1115], [1519, 1809], [865, 925]])\n",
    "corners[3] = np.array([[1755, 335], [2717, 783], [1981, 1677], [937, 999]])\n",
    "corners[4] = np.array([[1871, 265], [2713, 1073], [1877, 1949], [1021, 1089]])\n",
    "corners[5] = np.array([[2257, 281], [2767, 1259], [1365, 1687], [1073, 545]])\n",
    "corners[6] = np.array([[1727, 339], [2803, 777], [2139, 1803], [911, 1123]])\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 5))  # Adjust the figsize as needed\n",
    "axes = axes.ravel()  # Flatten the 2D array of axes for easy indexing\n",
    "\n",
    "for i in range(7):\n",
    "\n",
    "    filename = f\"img{i}.jpg\"\n",
    "    imgPath = os.path.join(dirFolder,'img', filename)\n",
    "\n",
    "    img = cv2.imread(imgPath)\n",
    "    \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    marker_num = find_aruco_num(img_gray, corners[i], aruco_marker)\n",
    "\n",
    "    image = cv2.putText(img_gray, f'Marker {marker_num}', (2200,300), cv2.FONT_HERSHEY_DUPLEX , 10, (255, 255, 255), 20, cv2.LINE_AA) \n",
    "\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(f'Marker {gt_marker[i]}')\n",
    "    axes[i].axis('off')  # To hide axes\n",
    "\n",
    "axes[7].axis('off')  # To hide axes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
