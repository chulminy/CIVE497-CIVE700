# Curated answers for Q5

**Q5. What kind of phone cameras or phone camera technologies will be introduced in next ten years? Talk freely** 

------------------------------------------------------------

**Q5: ** I think the most obvious technical change will be the increase of pixels in camera sensors.  This has been a trend since the beginning of cameras and there are only more reasons for this trend to continue - screens are getting larger with better resolutions therefore the extra pixels will actually be noticable on these new screens. 

Another likely change will be Time of Flight (TOF) technology, which is the use of structured-light sensors to get better 3D representations of the scene, which would be helpful for augmented reality and portrait applications. 

**Q5:** I believe that the following technologies have the potential to be the future of phone cameras:

* **Computational photography:** It’s increasingly apparent that computational photography — the combination of multiple images and related sensor data — is going to be the next big thing in smartphone cameras. Google and Apple have spent the past several years leveraging their phones’ computer-like chips to produce real-time photo and video results that dedicated cameras can’t offer, and the results are increasingly impressive. Perhaps the most significant are Android’s Night Sight and iOS’s Night Mode photos, which look as if they were snapped in daylight. Furthermore, Apple also added a feature to the iPhone 11 and iPhone 11 Pro called Deep Fusion, which automatically and instantly combines pieces from multiple pictures to create a single photo with pixel-level texture details that look as if they came off of heavy, expensive DSLRs. Skin, fabric, and other surfaces that might look soft are instead rendered with more precision. The next round of machine learning-added computational photography will be seen in both photos and videos. At the Snapdragon Tech Summit, Qualcomm showed off a Snapdragon 865 AI-enabled “image segmentation” feature powered by Morpho software. The result will be visual enhancements similar to Snapchat’s AR filters, only at much higher resolutions — and with more serious applications.

![](https://venturebeat.com/wp-content/uploads/2018/11/pjimage-1.jpg?resize=1024%2c683&strip=all?w=1200&strip=all)
Google’s Night Sight enabled on the left; disabled on the right.

![](https://venturebeat.com/wp-content/uploads/2019/10/deepfusion.jpg?resize=1024%2c512&strip=all?w=1200&strip=all)
Apple’s Deep Fusion computational photography feature turned off and on.

![](https://venturebeat.com/wp-content/uploads/2019/12/IMG_6480.jpeg?resize=1024%2C821&strip=all?w=1536&strip=all)
Visualisation of the image segmentation feature.

* **Augmented reality:** The value of depth-sensing cameras in future smartphones is going to play an important role in the coming years. That depth information can be used to scan real items into 3D versions, create 3D representations of scenes, and map real spaces for “augmented reality” insertion of digital items. There are different ways to gather depth data, including Google’s latest computational photography tricks, which require only a single regular camera, but using a proper depth sensor (such as the time-of-flight sensors on some high-end Samsung and LG phones) makes a huge difference. Samsung has already shown off an app that can scan a real teddy bear and turn it into an animated 3D object a person can control. While current iPhones (and iPad Pros) have depth-sensing front TrueDepth cameras, those only work at sub-2-foot distances, so newer designs should dramatically expand the number and range of objects iPhones will be able to scan.

![](https://www.popsci.com/uploads/2019/08/31/E5VU2XRCYVUGSSCC7AVCF72SWM-1024x768.jpeg)

![](https://www.popsci.com/uploads/2019/08/31/VSMBOZPXKPB236SEBJBDJHSCZ4-1024x768.jpeg)

**Q5:** The most recent trend is the RGBW lenses. It is basically like an RGB lense, but with a dedicated white pixel added to the matrix. This allows for higher light sensitivity, which would allow for higher quality photos during low light settings. Currently, the colours of the captured images are different from the actual images due to the extra white layer that has to be processes and added on. However, future technologies will close that gap.


**Q5:** With improvements in ISO technologies, capturing high quality images in complete darkness may be possible in the next 10 years. Camera sizes may continue to shrink therefore purchasing a bulky and large camera will be less likely. Capturing high quality images while travelling at high speeds may be possible with further improvements in shutter speed, therefore reducing the need for a tripod. Finally, with the rise in Deep Learning and AI technologies, there are a wide range of potential applications. Camera features such as shutter button or focusing may not be required if such features can be activated through voice or gestures. DL technologies may allow digital zoom to zoom in without the loss of image quality, by predicting low level image details.

**Q5:** Here is the list: 

* **1. Scanning object composition by Hyperspectral imaging technology**

A basic function can be achieved with the help of "hyperspectral imaging techniques" used in remote sensing testing. In other words, the chemical composition of the material of the photographed object is judged by taking pictures. That is, by using a camera to emit a scanning spectrum that is invisible to the human eye, since different components absorb different spectra, the spectral information can reflect the differences in the physical structure and chemical composition inside the sample. Then, through a special database comparison, you can know the material composition of the object you photographed.

* **2. Real sense interactive camera**

The so-called "real sense" means that it does not "squeeze" the real 3D world into a photo like a general camera, but can recognize three-dimensional space through a camera, thereby realizing gesture operations and other interactions. Specifically, we can utilize gesture and finger motion sensing technology to manipulate and interact with virtual 3D objects in real life. In addition, it is also possible to use the three-dimensional facial information recorded by RealSense technology to perform face recognition, use the space object measurement that supports RealSense technology, and so on.

* **3. Under-screen pop-up camera**

The phone has an under-screen camera system, but the camera is not front-facing but rear-facing. That is to say, the front and rear cameras are integrated into the full-screen mobile phone system. The realization of screen camera technology requires the cooperation of precise components. First of all, when the camera is not activated, the front screen is a whole screen. When watching videos, browsing web pages, etc., you cannot see that there is a camera in this position; secondly, when the camera is activated, it is able to accurately capture the user's picture, and maintain a good effect, without delaying the user's operation to take pictures; finally, the front lens should also have a good performance in light processing, character recognition, etc.

**Q5:** I think 3D cameras and 360 cameras may be the future of phone cameras.

3D camera was not new to smartphone. LG launched its Optimus 3D P920 smartphone back in 2011 with a pair of cameras to create 3D images. It was not successful because 3D display was not common, and those 3D images captured have little use when sharing to others. Nowadays, VR and AR technology is getting more mature, and the concept of metaverse is becoming more real in these years, 3D images and videos may finally have a platform to share and enjoy.

360 camera has not yet been integrated to a phone, i think the reason is mainly its size. If the size of a 360 camera can be shrunken to fix into a phone, it will be fun. 360 camera is good at taking wide landscape shoots, group selfies and third person view videos. It is also good at productivity, like making room tour and taking 360 progress photos on construction sites.

**Q5:** Here is the list:  

* **Optical Image Stabilisation (OIS) technology** might be introduced to the phone camera industry. The lens "floats" inside the camera assembly. The OIS system stabilises the image or video by "shifting" the lens to counter the shakes.

* **High-resolution sensors with pixel binning** might be applied on the phone cameras, balancing resolution and light sensitivity. Samsung are deploying an algorithm-driven technique called pixel binning that enables high-resolution sensors (with a small pixel size) to perform better in low-light conditions.

* **Continuous optical zoom** might be introduced to allow users to shift between different focal lengths smoothly. This requires precise movement of lenses within small spaces without affecting image quality.

* **RGBW Sensors**: The camera sensor captures colour information through a mechanism called the Colour Filter Array (CFA). Traditional camera sensors use CFAs arranged in the Bayer format, which comprises a pattern of Red (R), Green (G), and Blue (B) filters. RGBW sensors add White (W) filters to the mix. 


**Q5: ** There are different views about the phone camera technologies that will be introduced in the next ten years. On the one hand, the cameras will be so advanced that they’ll threaten to obviate even higher-end SLRs [11]. There are only so many different kinds of lenses, so we’ll soon reach a point where adding more lenses adds nothing new. However, the real change will likely be the megapixel count; at the end of 2019 the highest resolution in a smartphone was 108MP in the Xiaomi Mi Note 10, but it looks like a number of phones in 2020 were gearing up to match that [12]. In contrast, Scientists have estimated that the human eye sees roughly 576MP (i.e., assuming perfect vision). Consequently, people don’t need cameras able to surpase the human eye limit. Nevertheless, megapixel count will almost certainly be more pronounced in 2030 [12]. Another belief is related to swapping out individual components of a phone like a camera sensor and lenses [11] while keeping the original device up to date with the latest hardware advancements.

Moreover, mirrorless (A digital camera that accepts different lenses but does not use a mirror to reflect the image into the viewfinder) smartphones are the future of camera design [13]. Notably, the most important features for phone cameras have always been the need for eye-poping images that look great on social media and design requirements. The latter involves low-cost, small, devices that have fixed lenses. Smartphone manufacturers are incorporating new and creative hardware designs to work alongside their software implementations [13]. Couple with that, there are many features that can be expected for future smartphone cameras. For example, augmented reality, this feature refers to mixing real-world views with graphics, just like the Pokémon-hunting mobile game, and Snapchat's animated face filters [15]. Depth-sensing cameras may be crucial to enhancing augmented reality, a jargony industry term that probably makes your eyes glaze over.; depth-sensing cameras make object detection much easier for future iPhones [14]. Another feature would be better lenses, the lens technology on our smartphones will just keep getting better [15]. Similarly, thermal imaging is very likely to be part of future smartphone technologies. In fact, Cat S60 super-though smartphone by Caterpillar has this feature already [15]. Additionally, the optical zoom would be incorporated into future smartphone cameras by including periscope-style optical zooms combined along with software to form a dual zoom [15].

[11] B. Dieter, A. Johnson, and C. Welch. The smartphone, circa 2031. The verge. Nov 1, 2021. Retrieved February 12, 2022, from https://www.theverge.com/22749341/smartphones-future-predictions

[12] T. Bedford. What could your future smartphone look like in 2030? techradar, January 01, 2020, Retrieved February 12, 2022, from https://www.techradar.com/news/what-could-your-future-smartphone-look-like-in-2030.

[13] M. Smith. If Mirrorless Is the Future of the Camera, then the Smartphone Is the Future of Photography. fstoppers, September 11, 2021, Retrieved February 12, 2022, from https://fstoppers.com/gear/if-mirrorless-future-camera-then-smartphone-future-photography-578158

[14] B.X. Chen. The Smartphone’s Future: It’s All About the Camera. The New York Times. August 30, 2017, Retrieved February 12, 2022, from https://www.nytimes.com/2017/08/30/technology/personaltech/future-smartphone-camera-augmented-reality.html

[15] Engadget. The future of the smartphone camera: where next? October 10, 2017, Retrieved February 12, 2022, from https://www.engadget.com/2017-07-10-future-of-smartphone-camera.html

**Q5:** In the next ten year, new technologies will be introduced to not only improve the existing problems but also free the imagniation in every aspects of photography. Some of the possible new techniques: 
  
* **Dual OIS** Optical Image Stabilisation technology can "shift" the lens builtin the camera to counter the shakes and avoide blurry and shaky images. 
  
* **Continous optical zoom**: This feature can allow the users to shift between different focal lengths smoothly wihout loosing image quality. 
  
* **Deeper optical zoom**: Capable on  DSLR camera with ultra telephoto prime lens -- can a smartphone do the same thing, but only with its "tiny body" or maybe just a few layers of extra pieces? 